{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program uses various libraries and machine learning techniques in order to analyze various text to detect fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #import pandas library\n",
    "import numpy as np #import numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDirectory = \"C:/Users/Aja58/OneDrive/Documents/BTicketAnalysis/\" #locating excel file from directory\n",
    "inputDirectory = workingDirectory + \"input/\" #create an input directory\n",
    "outputDirectory = workingDirectory + \"output/\" #create an output directory\n",
    "\n",
    "commentsFilepath = inputDirectory + \"news.xlsx\" #Create a new filepath for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we read from our Excel file and put the data into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 131</th>\n",
       "      <th>Unnamed: 132</th>\n",
       "      <th>Unnamed: 133</th>\n",
       "      <th>Unnamed: 134</th>\n",
       "      <th>Unnamed: 135</th>\n",
       "      <th>Unnamed: 136</th>\n",
       "      <th>Unnamed: 137</th>\n",
       "      <th>Unnamed: 138</th>\n",
       "      <th>Unnamed: 139</th>\n",
       "      <th>Unnamed: 140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">news</th>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillaryâ€™s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>â€” Kaydee King (@KaydeeKing) November 9, 2016...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "news 0       8476                     You Can Smell Hillaryâ€™s Fear   \n",
       "     1      10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "     2       3608        Kerry to go to Paris in gesture of sympathy   \n",
       "     3      10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "     4        875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                     text label Unnamed: 4  \\\n",
       "news 0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE        NaN   \n",
       "     1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE        NaN   \n",
       "     2  U.S. Secretary of State John F. Kerry said Mon...  REAL        NaN   \n",
       "     3  â€” Kaydee King (@KaydeeKing) November 9, 2016...  FAKE        NaN   \n",
       "     4  It's primary day in New York and front-runners...  REAL        NaN   \n",
       "\n",
       "       Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ...  \\\n",
       "news 0        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "     1        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "     2        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "     3        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "     4        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "\n",
       "       Unnamed: 131 Unnamed: 132 Unnamed: 133 Unnamed: 134 Unnamed: 135  \\\n",
       "news 0          NaN          NaN          NaN          NaN          NaN   \n",
       "     1          NaN          NaN          NaN          NaN          NaN   \n",
       "     2          NaN          NaN          NaN          NaN          NaN   \n",
       "     3          NaN          NaN          NaN          NaN          NaN   \n",
       "     4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       Unnamed: 136 Unnamed: 137 Unnamed: 138 Unnamed: 139 Unnamed: 140  \n",
       "news 0          NaN          NaN          NaN          NaN          NaN  \n",
       "     1          NaN          NaN          NaN          NaN          NaN  \n",
       "     2          NaN          NaN          NaN          NaN          NaN  \n",
       "     3          NaN          NaN          NaN          NaN          NaN  \n",
       "     4          NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(pd.read_excel(commentsFilepath, sheet_name = None), ignore_index = False)#calling upon news excel file\n",
    "df.shape #gives us our array\n",
    "df.head() #returns first five rows of the excel news file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">news</th>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillaryâ€™s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>â€” Kaydee King (@KaydeeKing) November 9, 2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>The â€˜Pâ€™ in PBS Should Stand for â€˜Plutocr...</td>\n",
       "      <td>The â€˜Pâ€™ in PBS Should Stand for â€˜Plutocr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia â€”President Obama conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "news 0                        You Can Smell Hillaryâ€™s Fear   \n",
       "     1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "     2           Kerry to go to Paris in gesture of sympathy   \n",
       "     3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "     4      The Battle of New York: Why This Primary Matters   \n",
       "...                                                      ...   \n",
       "     7813  State Department says it can't find emails fro...   \n",
       "     7814  The â€˜Pâ€™ in PBS Should Stand for â€˜Plutocr...   \n",
       "     7815  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "     7816  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "     7817  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                        text  \n",
       "news 0     Daniel Greenfield, a Shillman Journalism Fello...  \n",
       "     1     Google Pinterest Digg Linkedin Reddit Stumbleu...  \n",
       "     2     U.S. Secretary of State John F. Kerry said Mon...  \n",
       "     3     â€” Kaydee King (@KaydeeKing) November 9, 2016...  \n",
       "     4     It's primary day in New York and front-runners...  \n",
       "...                                                      ...  \n",
       "     7813  The State Department told the Republican Natio...  \n",
       "     7814  The â€˜Pâ€™ in PBS Should Stand for â€˜Plutocr...  \n",
       "     7815   Anti-Trump Protesters Are Tools of the Oligar...  \n",
       "     7816  ADDIS ABABA, Ethiopia â€”President Obama conve...  \n",
       "     7817  Jeb Bush Is Suddenly Attacking Trump. Here's W...  \n",
       "\n",
       "[7818 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the only data we really need are the \"title\" and \"text\" columns.\n",
    "\n",
    "df1 = df[['title', 'text']]#keeping the aforementioned columns and dropping the rest, creates new dataframe.\n",
    "df1.shape #array\n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now import functions from our sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline #importing Pipeline from sklearn library, making our data easier to read.\n",
    "from sklearn.pipeline import make_pipeline #construct pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer #fills in any missing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier #looks for the five nearest neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('col_selector', ColumnSelector(cols='text', drop_axis=True)),\n",
       "                ('tfidf', TfidfVectorizer()),\n",
       "                ('kMeans', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ColumnSelector #will be used when we select column to work off of\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #counts as CountVectorizer and TfidfVectorizer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipe = Pipeline([ #create our pipeline\n",
    "    ('vect', TfidfVectorizer()), #will transform text into vector, given frequency of the word\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "df_Xtrain = pd.DataFrame({'text': ['REAL']*10,\n",
    "                         'label': 0})\n",
    "y_train = df_Xtrain['label'].to_numpy().ravel()\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col_selector', ColumnSelector(cols=('text'),drop_axis=True)),\n",
    "      ('tfidf', TfidfVectorizer()),\n",
    "    ('kMeans', KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "pipe.fit(df_Xtrain,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('col_selector', ColumnSelector(cols='text', drop_axis=True)),\n",
      "                ('tfidf', TfidfVectorizer()),\n",
      "                ('kMeans', KNeighborsClassifier())])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "text = Pipeline(steps=[('col_selector', ColumnSelector(cols='text', drop_axis=True)),\n",
    "                 ('tfidf', TfidfVectorizer()), ('kMeans', KNeighborsClassifier())])\n",
    "\n",
    "kMeansModel = text.fit(df_Xtrain,y_train)\n",
    "print(kMeansModel)\n",
    "print(kMeansModel.score(df_Xtrain,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using tfidfvectorizer, we get a 1.0 which means our text data is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now train model for\"title\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('col_selector', ColumnSelector(cols='title', drop_axis=True)),\n",
       "                ('tfidf', TfidfVectorizer()),\n",
       "                ('kMeans', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xtrain2 = pd.DataFrame({'title': ['REAL']*10,\n",
    "                          'label': 0})\n",
    "y_train2 = df_Xtrain['label'].to_numpy().ravel()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col_selector', ColumnSelector(cols=('title'),drop_axis=True)),\n",
    "    ('tfidf', TfidfVectorizer()), #uses both a count vectorizer and tfidf transformer\n",
    "    ('kMeans', KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "pipe.fit(df_Xtrain2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('col_selector', ColumnSelector(cols='title', drop_axis=True)),\n",
      "                ('tfidf', TfidfVectorizer()),\n",
      "                ('kMeans', KNeighborsClassifier())])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "title = Pipeline(steps=[('col_selector', ColumnSelector(cols='title', drop_axis=True)),\n",
    "                 ('tfidf', TfidfVectorizer()), ('kMeans', KNeighborsClassifier())])\n",
    "\n",
    "kMeansModel = title.fit(df_Xtrain2,y_train2)\n",
    "print(kMeansModel)\n",
    "print(kMeansModel.score(df_Xtrain2,y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likewise, using tfidfvectorizer, we received a 1.0 which means our data for the \"title\" column is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>134936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>126506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>109829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>101219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218148</th>\n",
       "      <td>fix,\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218149</th>\n",
       "      <td>quarks,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218150</th>\n",
       "      <td>92-8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218151</th>\n",
       "      <td>antineutron,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218152</th>\n",
       "      <td>script.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Frequency\n",
       "0                the     254545\n",
       "1                 to     134936\n",
       "2                 of     126506\n",
       "3                and     109829\n",
       "4                  a     101219\n",
       "...              ...        ...\n",
       "218148         fix,\"          1\n",
       "218149       quarks,          1\n",
       "218150          92-8          1\n",
       "218151  antineutron,          1\n",
       "218152      script.\"          1\n",
       "\n",
       "[218153 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_count = df1.text.str.split(expand=True).stack().value_counts().reset_index()#Word Count of words in text column before pre-processing\n",
    "\n",
    "df1_count.columns = ['Word', 'Frequency']\n",
    "\n",
    "df1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>Confound</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20470</th>\n",
       "      <td>(At</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>Some)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>cock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>Suddenly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20474 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "0           the       1900\n",
       "1            to       1614\n",
       "2            of       1215\n",
       "3            in       1070\n",
       "4           The        954\n",
       "...         ...        ...\n",
       "20469  Confound          1\n",
       "20470       (At          1\n",
       "20471     Some)          1\n",
       "20472      cock          1\n",
       "20473  Suddenly          1\n",
       "\n",
       "[20474 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_count = df1.title.str.split(expand=True).stack().value_counts().reset_index()#Word Count of words in title column before pre-processing\n",
    "\n",
    "df1_count.columns = ['Word', 'Frequency']\n",
    "\n",
    "df1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a lot of \"stopwords\", such as \"the\", \"to\" \"of\", etc. in both our text and title columns, which provide little to no valuable information to the model. Similarly, converting all characters to lowercase will allow us to achieve more helpful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\1080283383.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['text'] = df1['text'].str.lower()\n",
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\1080283383.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['title'] = df1['title'].str.lower()#makes everything in text and title column lowercase\n"
     ]
    }
   ],
   "source": [
    "#TEXT PREPROCESSING PORTION\n",
    "#Start by making all characters in our \"text\" and \"title\" columns lowercase.\n",
    "\n",
    "df1['text'] = df1['text'].str.lower()\n",
    "df1['title'] = df1['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\2165309834.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df1['text'] = df1.text.str.replace('[^0-9a-zA-Z ]+' , '')\n",
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\2165309834.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['text'] = df1.text.str.replace('[^0-9a-zA-Z ]+' , '')\n",
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\2165309834.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df1['title'] = df1.title.str.replace('[^0-9a-zA-Z ]+' , '')\n",
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\2165309834.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['title'] = df1.title.str.replace('[^0-9a-zA-Z ]+' , '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">news</th>\n",
       "      <th>0</th>\n",
       "      <td>you can smell hillarys fear</td>\n",
       "      <td>daniel greenfield a shillman journalism fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watch the exact moment paul ryan committed pol...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kerry to go to paris in gesture of sympathy</td>\n",
       "      <td>us secretary of state john f kerry said monday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernie supporters on twitter erupt in anger ag...</td>\n",
       "      <td>kaydee king kaydeeking november 9 2016 the le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the battle of new york why this primary matters</td>\n",
       "      <td>its primary day in new york and frontrunners h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>state department says it cant find emails from...</td>\n",
       "      <td>the state department told the republican natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>the p in pbs should stand for plutocratic or p...</td>\n",
       "      <td>the p in pbs should stand for plutocratic or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>antitrump protesters are tools of the oligarch...</td>\n",
       "      <td>antitrump protesters are tools of the oligarc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>in ethiopia obama seeks progress on peace secu...</td>\n",
       "      <td>addis ababa ethiopia president obama convened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>jeb bush is suddenly attacking trump heres why...</td>\n",
       "      <td>jeb bush is suddenly attacking trump heres why...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "news 0                           you can smell hillarys fear   \n",
       "     1     watch the exact moment paul ryan committed pol...   \n",
       "     2           kerry to go to paris in gesture of sympathy   \n",
       "     3     bernie supporters on twitter erupt in anger ag...   \n",
       "     4       the battle of new york why this primary matters   \n",
       "...                                                      ...   \n",
       "     7813  state department says it cant find emails from...   \n",
       "     7814  the p in pbs should stand for plutocratic or p...   \n",
       "     7815  antitrump protesters are tools of the oligarch...   \n",
       "     7816  in ethiopia obama seeks progress on peace secu...   \n",
       "     7817  jeb bush is suddenly attacking trump heres why...   \n",
       "\n",
       "                                                        text  \n",
       "news 0     daniel greenfield a shillman journalism fellow...  \n",
       "     1     google pinterest digg linkedin reddit stumbleu...  \n",
       "     2     us secretary of state john f kerry said monday...  \n",
       "     3      kaydee king kaydeeking november 9 2016 the le...  \n",
       "     4     its primary day in new york and frontrunners h...  \n",
       "...                                                      ...  \n",
       "     7813  the state department told the republican natio...  \n",
       "     7814  the p in pbs should stand for plutocratic or p...  \n",
       "     7815   antitrump protesters are tools of the oligarc...  \n",
       "     7816  addis ababa ethiopia president obama convened ...  \n",
       "     7817  jeb bush is suddenly attacking trump heres why...  \n",
       "\n",
       "[7818 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will now remove all non-alphanumeric characters. Certain characters and symbols provide very little valuable information to the model.\n",
    "\n",
    "df1['text'] = df1.text.str.replace('[^0-9a-zA-Z ]+' , '')\n",
    "df1['title'] = df1.title.str.replace('[^0-9a-zA-Z ]+' , '')\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now import a list of stopwords from the nltk library. Stopwords provide little to no valuable information to our model. It is best to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aja58\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords#gives us our list of stopwords\n",
    "\" \".join(stopwords.words('english'))\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words#list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\3866130103.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['text'] = df1['text'].apply(lambda x : remove_stop(x))#applies the removal of stopwords\n"
     ]
    }
   ],
   "source": [
    "def remove_stop(x):\n",
    "    return \" \".join([word for word in str(x).split() if word not in stop_words])#removes stopwords\n",
    "df1['text'] = df1['text'].apply(lambda x : remove_stop(x))#applies the removal of stopwords to the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">news</th>\n",
       "      <th>0</th>\n",
       "      <td>you can smell hillarys fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watch the exact moment paul ryan committed pol...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kerry to go to paris in gesture of sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernie supporters on twitter erupt in anger ag...</td>\n",
       "      <td>kaydee king kaydeeking november 9 2016 lesson ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the battle of new york why this primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>state department says it cant find emails from...</td>\n",
       "      <td>state department told republican national comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>the p in pbs should stand for plutocratic or p...</td>\n",
       "      <td>p pbs stand plutocratic pentagon posted oct 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>antitrump protesters are tools of the oligarch...</td>\n",
       "      <td>antitrump protesters tools oligarchy reform al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>in ethiopia obama seeks progress on peace secu...</td>\n",
       "      <td>addis ababa ethiopia president obama convened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>jeb bush is suddenly attacking trump heres why...</td>\n",
       "      <td>jeb bush suddenly attacking trump heres matter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "news 0                           you can smell hillarys fear   \n",
       "     1     watch the exact moment paul ryan committed pol...   \n",
       "     2           kerry to go to paris in gesture of sympathy   \n",
       "     3     bernie supporters on twitter erupt in anger ag...   \n",
       "     4       the battle of new york why this primary matters   \n",
       "...                                                      ...   \n",
       "     7813  state department says it cant find emails from...   \n",
       "     7814  the p in pbs should stand for plutocratic or p...   \n",
       "     7815  antitrump protesters are tools of the oligarch...   \n",
       "     7816  in ethiopia obama seeks progress on peace secu...   \n",
       "     7817  jeb bush is suddenly attacking trump heres why...   \n",
       "\n",
       "                                                        text  \n",
       "news 0     daniel greenfield shillman journalism fellow f...  \n",
       "     1     google pinterest digg linkedin reddit stumbleu...  \n",
       "     2     us secretary state john f kerry said monday st...  \n",
       "     3     kaydee king kaydeeking november 9 2016 lesson ...  \n",
       "     4     primary day new york frontrunners hillary clin...  \n",
       "...                                                      ...  \n",
       "     7813  state department told republican national comm...  \n",
       "     7814  p pbs stand plutocratic pentagon posted oct 27...  \n",
       "     7815  antitrump protesters tools oligarchy reform al...  \n",
       "     7816  addis ababa ethiopia president obama convened ...  \n",
       "     7817  jeb bush suddenly attacking trump heres matter...  \n",
       "\n",
       "[7818 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\1639901177.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['title'] = df1['title'].apply(lambda x : remove_stop(x))#removes stopwords in title column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">news</th>\n",
       "      <th>0</th>\n",
       "      <td>smell hillarys fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november 9 2016 lesson ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>state department says cant find emails clinton...</td>\n",
       "      <td>state department told republican national comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>p pbs stand plutocratic pentagon</td>\n",
       "      <td>p pbs stand plutocratic pentagon posted oct 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>antitrump protesters tools oligarchy information</td>\n",
       "      <td>antitrump protesters tools oligarchy reform al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>ethiopia obama seeks progress peace security e...</td>\n",
       "      <td>addis ababa ethiopia president obama convened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>jeb bush suddenly attacking trump heres matters</td>\n",
       "      <td>jeb bush suddenly attacking trump heres matter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "news 0                                   smell hillarys fear   \n",
       "     1     watch exact moment paul ryan committed politic...   \n",
       "     2                       kerry go paris gesture sympathy   \n",
       "     3     bernie supporters twitter erupt anger dnc trie...   \n",
       "     4                       battle new york primary matters   \n",
       "...                                                      ...   \n",
       "     7813  state department says cant find emails clinton...   \n",
       "     7814                   p pbs stand plutocratic pentagon   \n",
       "     7815   antitrump protesters tools oligarchy information   \n",
       "     7816  ethiopia obama seeks progress peace security e...   \n",
       "     7817    jeb bush suddenly attacking trump heres matters   \n",
       "\n",
       "                                                        text  \n",
       "news 0     daniel greenfield shillman journalism fellow f...  \n",
       "     1     google pinterest digg linkedin reddit stumbleu...  \n",
       "     2     us secretary state john f kerry said monday st...  \n",
       "     3     kaydee king kaydeeking november 9 2016 lesson ...  \n",
       "     4     primary day new york frontrunners hillary clin...  \n",
       "...                                                      ...  \n",
       "     7813  state department told republican national comm...  \n",
       "     7814  p pbs stand plutocratic pentagon posted oct 27...  \n",
       "     7815  antitrump protesters tools oligarchy reform al...  \n",
       "     7816  addis ababa ethiopia president obama convened ...  \n",
       "     7817  jeb bush suddenly attacking trump heres matter...  \n",
       "\n",
       "[7818 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['title'] = df1['title'].apply(lambda x : remove_stop(x))#removes stopwords in title column\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after the removal of stopwords, we will now check the words and frequency of a word in the text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>18795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump</td>\n",
       "      <td>16691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clinton</td>\n",
       "      <td>13285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "      <td>12426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us</td>\n",
       "      <td>12016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139536</th>\n",
       "      <td>watchtower</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139537</th>\n",
       "      <td>defendantsdefining</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139538</th>\n",
       "      <td>supportspeaking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139539</th>\n",
       "      <td>saidkhizr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139540</th>\n",
       "      <td>studious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139541 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Word  Frequency\n",
       "0                     said      18795\n",
       "1                    trump      16691\n",
       "2                  clinton      13285\n",
       "3                    would      12426\n",
       "4                       us      12016\n",
       "...                    ...        ...\n",
       "139536          watchtower          1\n",
       "139537  defendantsdefining          1\n",
       "139538     supportspeaking          1\n",
       "139539           saidkhizr          1\n",
       "139540            studious          1\n",
       "\n",
       "[139541 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_count = df1.text.str.split(expand=True).stack().value_counts().reset_index()\n",
    "\n",
    "df1_count.columns = ['Word', 'Frequency']\n",
    "\n",
    "df1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we removed the stopwords, we get less generic words such as \"that\", \"the\", \"at\", etc. that can be applied anywhere. Now we get more specific words that can be deemed important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clinton</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hillary</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11951</th>\n",
       "      <td>boycottcomedianrobert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952</th>\n",
       "      <td>feelin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11953</th>\n",
       "      <td>deniro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11954</th>\n",
       "      <td>antarctic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11955</th>\n",
       "      <td>plutocratic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11956 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Word  Frequency\n",
       "0                      trump        943\n",
       "1                        nan        637\n",
       "2                    clinton        626\n",
       "3                    hillary        526\n",
       "4                         us        369\n",
       "...                      ...        ...\n",
       "11951  boycottcomedianrobert          1\n",
       "11952                 feelin          1\n",
       "11953                 deniro          1\n",
       "11954              antarctic          1\n",
       "11955            plutocratic          1\n",
       "\n",
       "[11956 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check word and frequency of the title column.\n",
    "\n",
    "df1_count = df1.title.str.split(expand=True).stack().value_counts().reset_index()\n",
    "\n",
    "df1_count.columns = ['Word', 'Frequency']\n",
    "\n",
    "df1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">news</th>\n",
       "      <th>0</th>\n",
       "      <td>smell hillarys fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november 9 2016 lesson ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>state department says cant find emails clinton...</td>\n",
       "      <td>state department told republican national comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>p pbs stand plutocratic pentagon</td>\n",
       "      <td>p pbs stand plutocratic pentagon posted oct 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>antitrump protesters tools oligarchy information</td>\n",
       "      <td>antitrump protesters tools oligarchy reform al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>ethiopia obama seeks progress peace security e...</td>\n",
       "      <td>addis ababa ethiopia president obama convened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>jeb bush suddenly attacking trump heres matters</td>\n",
       "      <td>jeb bush suddenly attacking trump heres matter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "news 0                                   smell hillarys fear   \n",
       "     1     watch exact moment paul ryan committed politic...   \n",
       "     2                       kerry go paris gesture sympathy   \n",
       "     3     bernie supporters twitter erupt anger dnc trie...   \n",
       "     4                       battle new york primary matters   \n",
       "...                                                      ...   \n",
       "     7813  state department says cant find emails clinton...   \n",
       "     7814                   p pbs stand plutocratic pentagon   \n",
       "     7815   antitrump protesters tools oligarchy information   \n",
       "     7816  ethiopia obama seeks progress peace security e...   \n",
       "     7817    jeb bush suddenly attacking trump heres matters   \n",
       "\n",
       "                                                        text  \n",
       "news 0     daniel greenfield shillman journalism fellow f...  \n",
       "     1     google pinterest digg linkedin reddit stumbleu...  \n",
       "     2     us secretary state john f kerry said monday st...  \n",
       "     3     kaydee king kaydeeking november 9 2016 lesson ...  \n",
       "     4     primary day new york frontrunners hillary clin...  \n",
       "...                                                      ...  \n",
       "     7813  state department told republican national comm...  \n",
       "     7814  p pbs stand plutocratic pentagon posted oct 27...  \n",
       "     7815  antitrump protesters tools oligarchy reform al...  \n",
       "     7816  addis ababa ethiopia president obama convened ...  \n",
       "     7817  jeb bush suddenly attacking trump heres matter...  \n",
       "\n",
       "[7818 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we want to start encoding to transform categorical values into numerical values. The machine can only work in numerical values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by importing encoder oriented functions from sklearn library.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #import more sklearn functions\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       title  \\\n",
      "news 0                                   smell hillarys fear   \n",
      "     1     watch exact moment paul ryan committed politic...   \n",
      "     2                       kerry go paris gesture sympathy   \n",
      "     3     bernie supporters twitter erupt anger dnc trie...   \n",
      "     4                       battle new york primary matters   \n",
      "...                                                      ...   \n",
      "     7813  state department says cant find emails clinton...   \n",
      "     7814                   p pbs stand plutocratic pentagon   \n",
      "     7815   antitrump protesters tools oligarchy information   \n",
      "     7816  ethiopia obama seeks progress peace security e...   \n",
      "     7817    jeb bush suddenly attacking trump heres matters   \n",
      "\n",
      "                                                        text  titles_encoded  \n",
      "news 0     daniel greenfield shillman journalism fellow f...            5651  \n",
      "     1     google pinterest digg linkedin reddit stumbleu...            6758  \n",
      "     2     us secretary state john f kerry said monday st...            3482  \n",
      "     3     kaydee king kaydeeking november 9 2016 lesson ...             634  \n",
      "     4     primary day new york frontrunners hillary clin...             559  \n",
      "...                                                      ...             ...  \n",
      "     7813  state department told republican national comm...            5747  \n",
      "     7814  p pbs stand plutocratic pentagon posted oct 27...            4585  \n",
      "     7815  antitrump protesters tools oligarchy reform al...             398  \n",
      "     7816  addis ababa ethiopia president obama convened ...            2068  \n",
      "     7817  jeb bush suddenly attacking trump heres matter...            3359  \n",
      "\n",
      "[7818 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\590820929.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['titles_encoded'] = labelencoder.fit_transform(df1['title'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4084    637\n",
       "0        14\n",
       "2184      5\n",
       "4543      5\n",
       "5064      5\n",
       "       ... \n",
       "1930      1\n",
       "4510      1\n",
       "2578      1\n",
       "5164      1\n",
       "3359      1\n",
       "Name: titles_encoded, Length: 7031, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder() #encodes our title column\n",
    "\n",
    "df1['titles_encoded'] = labelencoder.fit_transform(df1['title'])\n",
    "\n",
    "print(df1)\n",
    "df1['titles_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       title  \\\n",
      "news 0                                   smell hillarys fear   \n",
      "     1     watch exact moment paul ryan committed politic...   \n",
      "     2                       kerry go paris gesture sympathy   \n",
      "     3     bernie supporters twitter erupt anger dnc trie...   \n",
      "     4                       battle new york primary matters   \n",
      "...                                                      ...   \n",
      "     7813  state department says cant find emails clinton...   \n",
      "     7814                   p pbs stand plutocratic pentagon   \n",
      "     7815   antitrump protesters tools oligarchy information   \n",
      "     7816  ethiopia obama seeks progress peace security e...   \n",
      "     7817    jeb bush suddenly attacking trump heres matters   \n",
      "\n",
      "                                                        text  titles_encoded  \\\n",
      "news 0     daniel greenfield shillman journalism fellow f...            5651   \n",
      "     1     google pinterest digg linkedin reddit stumbleu...            6758   \n",
      "     2     us secretary state john f kerry said monday st...            3482   \n",
      "     3     kaydee king kaydeeking november 9 2016 lesson ...             634   \n",
      "     4     primary day new york frontrunners hillary clin...             559   \n",
      "...                                                      ...             ...   \n",
      "     7813  state department told republican national comm...            5747   \n",
      "     7814  p pbs stand plutocratic pentagon posted oct 27...            4585   \n",
      "     7815  antitrump protesters tools oligarchy reform al...             398   \n",
      "     7816  addis ababa ethiopia president obama convened ...            2068   \n",
      "     7817  jeb bush suddenly attacking trump heres matter...            3359   \n",
      "\n",
      "           text_encoded  \n",
      "news 0             1249  \n",
      "     1             2294  \n",
      "     2             6001  \n",
      "     3             3037  \n",
      "     4             4518  \n",
      "...                 ...  \n",
      "     7813          5375  \n",
      "     7814          4040  \n",
      "     7815           393  \n",
      "     7816           265  \n",
      "     7817          2931  \n",
      "\n",
      "[7818 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\1272914007.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['text_encoded'] = labelencoder.fit_transform(df1['text'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3582    893\n",
       "3054     58\n",
       "0        39\n",
       "6033     23\n",
       "1680     17\n",
       "       ... \n",
       "827       1\n",
       "5046      1\n",
       "3966      1\n",
       "2974      1\n",
       "2931      1\n",
       "Name: text_encoded, Length: 6634, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df1['text_encoded'] = labelencoder.fit_transform(df1['text'])\n",
    "\n",
    "print(df1)\n",
    "df1['text_encoded'].value_counts()#encodes our text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After encoding our \"text\" and \"title\" columns, the machine now has its information in numerical values. We now must use an imputer to fill in missing values (NAN) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        title  text  titles_encoded  text_encoded\n",
      "news 0   5651  1249            5651          1249\n",
      "     1   6758  2294            6758          2294\n",
      "     2   3482  6001            3482          6001\n",
      "     3    634  3037             634          3037\n",
      "     4    559  4518             559          4518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\2507572102.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[['text', 'title']] = imputer.fit_transform(df1[['text_encoded', 'titles_encoded']])#applying the imputer to the select columns\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')#replaces NAN values with most frequent values\n",
    "\n",
    "df1[['text', 'title']] = imputer.fit_transform(df1[['text_encoded', 'titles_encoded']])#applying the imputer to the select columns\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now try encoding using the \"OneHotEncoder\" function, which will take numerical features into \"dummy\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[array([   0,    1,    2, ..., 6631, 6632, 6633])]\n",
      "        title  text  titles_encoded  text_encoded\n",
      "news 0   5651  1249            5651          1249\n",
      "     1   6758  2294            6758          2294\n",
      "     2   3482  6001            3482          6001\n",
      "     3    634  3037             634          3037\n",
      "     4    559  4518             559          4518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder#will make categories of the values in the targetnames column\n",
    "\n",
    "oHE = OneHotEncoder()\n",
    "\n",
    "transformed = oHE.fit_transform(df1['text_encoded'].to_numpy().reshape(-1,1))\n",
    "\n",
    "print(transformed.toarray()[:10])\n",
    "print(oHE.categories_)\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the OneHotEncoder function resulted in a lot of 0s. This could be do to a significant amount of stopwords in the original \"text\" and \"title\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7818, 6637)\n",
      "Index(['title', 'text', 'titles_encoded', 'text_encoded_0', 'text_encoded_1',\n",
      "       'text_encoded_2', 'text_encoded_3', 'text_encoded_4', 'text_encoded_5',\n",
      "       'text_encoded_6',\n",
      "       ...\n",
      "       'text_encoded_6624', 'text_encoded_6625', 'text_encoded_6626',\n",
      "       'text_encoded_6627', 'text_encoded_6628', 'text_encoded_6629',\n",
      "       'text_encoded_6630', 'text_encoded_6631', 'text_encoded_6632',\n",
      "       'text_encoded_6633'],\n",
      "      dtype='object', length=6637)\n",
      "        title  text  titles_encoded  text_encoded_0  text_encoded_1  \\\n",
      "news 0   5651  1249            5651               0               0   \n",
      "     1   6758  2294            6758               0               0   \n",
      "     2   3482  6001            3482               0               0   \n",
      "     3    634  3037             634               0               0   \n",
      "     4    559  4518             559               0               0   \n",
      "\n",
      "        text_encoded_2  text_encoded_3  text_encoded_4  text_encoded_5  \\\n",
      "news 0               0               0               0               0   \n",
      "     1               0               0               0               0   \n",
      "     2               0               0               0               0   \n",
      "     3               0               0               0               0   \n",
      "     4               0               0               0               0   \n",
      "\n",
      "        text_encoded_6  ...  text_encoded_6624  text_encoded_6625  \\\n",
      "news 0               0  ...                  0                  0   \n",
      "     1               0  ...                  0                  0   \n",
      "     2               0  ...                  0                  0   \n",
      "     3               0  ...                  0                  0   \n",
      "     4               0  ...                  0                  0   \n",
      "\n",
      "        text_encoded_6626  text_encoded_6627  text_encoded_6628  \\\n",
      "news 0                  0                  0                  0   \n",
      "     1                  0                  0                  0   \n",
      "     2                  0                  0                  0   \n",
      "     3                  0                  0                  0   \n",
      "     4                  0                  0                  0   \n",
      "\n",
      "        text_encoded_6629  text_encoded_6630  text_encoded_6631  \\\n",
      "news 0                  0                  0                  0   \n",
      "     1                  0                  0                  0   \n",
      "     2                  0                  0                  0   \n",
      "     3                  0                  0                  0   \n",
      "     4                  0                  0                  0   \n",
      "\n",
      "        text_encoded_6632  text_encoded_6633  \n",
      "news 0                  0                  0  \n",
      "     1                  0                  0  \n",
      "     2                  0                  0  \n",
      "     3                  0                  0  \n",
      "     4                  0                  0  \n",
      "\n",
      "[5 rows x 6637 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x = pd.get_dummies(df1, columns =['text_encoded'])#gives us 1's and 0's which will tell us if it matches with the column header\n",
    "print(train_x.shape)\n",
    "print(train_x.columns)\n",
    "print(train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7818, 7034)\n",
      "Index(['title', 'text', 'text_encoded', 'titles_encoded_0', 'titles_encoded_1',\n",
      "       'titles_encoded_2', 'titles_encoded_3', 'titles_encoded_4',\n",
      "       'titles_encoded_5', 'titles_encoded_6',\n",
      "       ...\n",
      "       'titles_encoded_7021', 'titles_encoded_7022', 'titles_encoded_7023',\n",
      "       'titles_encoded_7024', 'titles_encoded_7025', 'titles_encoded_7026',\n",
      "       'titles_encoded_7027', 'titles_encoded_7028', 'titles_encoded_7029',\n",
      "       'titles_encoded_7030'],\n",
      "      dtype='object', length=7034)\n",
      "        title  text  text_encoded  titles_encoded_0  titles_encoded_1  \\\n",
      "news 0   5651  1249          1249                 0                 0   \n",
      "     1   6758  2294          2294                 0                 0   \n",
      "     2   3482  6001          6001                 0                 0   \n",
      "     3    634  3037          3037                 0                 0   \n",
      "     4    559  4518          4518                 0                 0   \n",
      "\n",
      "        titles_encoded_2  titles_encoded_3  titles_encoded_4  \\\n",
      "news 0                 0                 0                 0   \n",
      "     1                 0                 0                 0   \n",
      "     2                 0                 0                 0   \n",
      "     3                 0                 0                 0   \n",
      "     4                 0                 0                 0   \n",
      "\n",
      "        titles_encoded_5  titles_encoded_6  ...  titles_encoded_7021  \\\n",
      "news 0                 0                 0  ...                    0   \n",
      "     1                 0                 0  ...                    0   \n",
      "     2                 0                 0  ...                    0   \n",
      "     3                 0                 0  ...                    0   \n",
      "     4                 0                 0  ...                    0   \n",
      "\n",
      "        titles_encoded_7022  titles_encoded_7023  titles_encoded_7024  \\\n",
      "news 0                    0                    0                    0   \n",
      "     1                    0                    0                    0   \n",
      "     2                    0                    0                    0   \n",
      "     3                    0                    0                    0   \n",
      "     4                    0                    0                    0   \n",
      "\n",
      "        titles_encoded_7025  titles_encoded_7026  titles_encoded_7027  \\\n",
      "news 0                    0                    0                    0   \n",
      "     1                    0                    0                    0   \n",
      "     2                    0                    0                    0   \n",
      "     3                    0                    0                    0   \n",
      "     4                    0                    0                    0   \n",
      "\n",
      "        titles_encoded_7028  titles_encoded_7029  titles_encoded_7030  \n",
      "news 0                    0                    0                    0  \n",
      "     1                    0                    0                    0  \n",
      "     2                    0                    0                    0  \n",
      "     3                    0                    0                    0  \n",
      "     4                    0                    0                    0  \n",
      "\n",
      "[5 rows x 7034 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x = pd.get_dummies(df1, columns =['titles_encoded'])#gives us 1's and 0's which will tell us if it matches with the column header\n",
    "print(train_x.shape)\n",
    "print(train_x.columns)\n",
    "print(train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        title  text  titles_encoded  text_encoded\n",
      "news 0   5651  1249            5651          1249\n",
      "     1   6758  2294            6758          2294\n",
      "     2   3482  6001            3482          6001\n",
      "     3    634  3037             634          3037\n",
      "     4    559  4518             559          4518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\2507572102.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[['text', 'title']] = imputer.fit_transform(df1[['text_encoded', 'titles_encoded']])#applying the imputer to the select columns\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')#replaces NAN values with most frequent values\n",
    "\n",
    "df1[['text', 'title']] = imputer.fit_transform(df1[['text_encoded', 'titles_encoded']])#applying the imputer to the select columns\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        title  text  titles_encoded  text_encoded\n",
      "news 0   5651  1249        1.073235     -1.152734\n",
      "     1   6758  2294        1.639662     -0.574249\n",
      "     2   3482  6001       -0.036594      1.477849\n",
      "     3    634  3037       -1.493851     -0.162944\n",
      "     4    559  4518       -1.532227      0.656899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aja58\\AppData\\Local\\Temp\\ipykernel_6148\\987694671.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[columnsToTransform] = standardScaler.fit_transform(df1[columnsToTransform])\n"
     ]
    }
   ],
   "source": [
    "#standardize the data \n",
    "\n",
    "standardScaler = StandardScaler()#applying the scaling. measures standard deviation of the values\n",
    "\n",
    "columnsToTransform = ['text_encoded', 'titles_encoded']\n",
    "\n",
    "df1[columnsToTransform] = standardScaler.fit_transform(df1[columnsToTransform])\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we must check the mean and standard deviation of the dat after standardizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_encoded     -6.191574e-17\n",
       "titles_encoded   -1.483688e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df1[columnsToTransform], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mean of both the encoded title column and encoded text column are very close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_encoded      1.0\n",
       "titles_encoded    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(df1[columnsToTransform], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our standard deviation of both the encoded text column and encoded title column are 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[array([-1.84414742, -1.84359385, -1.84304027, ...,  1.82660031,\n",
      "        1.82715388,  1.82770746])]\n",
      "        title  text  titles_encoded  text_encoded\n",
      "news 0   5651  1249        1.073235     -1.152734\n",
      "     1   6758  2294        1.639662     -0.574249\n",
      "     2   3482  6001       -0.036594      1.477849\n",
      "     3    634  3037       -1.493851     -0.162944\n",
      "     4    559  4518       -1.532227      0.656899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder#will make categories of the values in the targetnames column\n",
    "\n",
    "oHE = OneHotEncoder()\n",
    "\n",
    "transformed = oHE.fit_transform(df1['text_encoded'].to_numpy().reshape(-1,1))\n",
    "\n",
    "print(transformed.toarray()[:10])\n",
    "print(oHE.categories_)\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7818, 13667)\n",
      "Index(['title', 'text', 'text_encoded_-1.8441474219311518',\n",
      "       'text_encoded_-1.8435938481518628', 'text_encoded_-1.843040274372574',\n",
      "       'text_encoded_-1.842486700593285', 'text_encoded_-1.841933126813996',\n",
      "       'text_encoded_-1.841379553034707', 'text_encoded_-1.8408259792554182',\n",
      "       'text_encoded_-1.8402724054761292',\n",
      "       ...\n",
      "       'titles_encoded_1.7742333879189238',\n",
      "       'titles_encoded_1.7747450655042567',\n",
      "       'titles_encoded_1.7752567430895894',\n",
      "       'titles_encoded_1.7757684206749222', 'titles_encoded_1.776280098260255',\n",
      "       'titles_encoded_1.7767917758455878',\n",
      "       'titles_encoded_1.7773034534309204',\n",
      "       'titles_encoded_1.7778151310162533', 'titles_encoded_1.778326808601586',\n",
      "       'titles_encoded_1.7788384861869189'],\n",
      "      dtype='object', length=13667)\n",
      "        title  text  text_encoded_-1.8441474219311518  \\\n",
      "news 0   5651  1249                                 0   \n",
      "     1   6758  2294                                 0   \n",
      "     2   3482  6001                                 0   \n",
      "     3    634  3037                                 0   \n",
      "     4    559  4518                                 0   \n",
      "\n",
      "        text_encoded_-1.8435938481518628  text_encoded_-1.843040274372574  \\\n",
      "news 0                                 0                                0   \n",
      "     1                                 0                                0   \n",
      "     2                                 0                                0   \n",
      "     3                                 0                                0   \n",
      "     4                                 0                                0   \n",
      "\n",
      "        text_encoded_-1.842486700593285  text_encoded_-1.841933126813996  \\\n",
      "news 0                                0                                0   \n",
      "     1                                0                                0   \n",
      "     2                                0                                0   \n",
      "     3                                0                                0   \n",
      "     4                                0                                0   \n",
      "\n",
      "        text_encoded_-1.841379553034707  text_encoded_-1.8408259792554182  \\\n",
      "news 0                                0                                 0   \n",
      "     1                                0                                 0   \n",
      "     2                                0                                 0   \n",
      "     3                                0                                 0   \n",
      "     4                                0                                 0   \n",
      "\n",
      "        text_encoded_-1.8402724054761292  ...  \\\n",
      "news 0                                 0  ...   \n",
      "     1                                 0  ...   \n",
      "     2                                 0  ...   \n",
      "     3                                 0  ...   \n",
      "     4                                 0  ...   \n",
      "\n",
      "        titles_encoded_1.7742333879189238  titles_encoded_1.7747450655042567  \\\n",
      "news 0                                  0                                  0   \n",
      "     1                                  0                                  0   \n",
      "     2                                  0                                  0   \n",
      "     3                                  0                                  0   \n",
      "     4                                  0                                  0   \n",
      "\n",
      "        titles_encoded_1.7752567430895894  titles_encoded_1.7757684206749222  \\\n",
      "news 0                                  0                                  0   \n",
      "     1                                  0                                  0   \n",
      "     2                                  0                                  0   \n",
      "     3                                  0                                  0   \n",
      "     4                                  0                                  0   \n",
      "\n",
      "        titles_encoded_1.776280098260255  titles_encoded_1.7767917758455878  \\\n",
      "news 0                                 0                                  0   \n",
      "     1                                 0                                  0   \n",
      "     2                                 0                                  0   \n",
      "     3                                 0                                  0   \n",
      "     4                                 0                                  0   \n",
      "\n",
      "        titles_encoded_1.7773034534309204  titles_encoded_1.7778151310162533  \\\n",
      "news 0                                  0                                  0   \n",
      "     1                                  0                                  0   \n",
      "     2                                  0                                  0   \n",
      "     3                                  0                                  0   \n",
      "     4                                  0                                  0   \n",
      "\n",
      "        titles_encoded_1.778326808601586  titles_encoded_1.7788384861869189  \n",
      "news 0                                 0                                  0  \n",
      "     1                                 0                                  0  \n",
      "     2                                 0                                  0  \n",
      "     3                                 0                                  0  \n",
      "     4                                 0                                  0  \n",
      "\n",
      "[5 rows x 13667 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x = pd.get_dummies(df1, columns =['text_encoded', 'titles_encoded'])#gives us 1's and 0's which will tell us if it matches with the column header\n",
    "print(train_x.shape)\n",
    "print(train_x.columns)\n",
    "print(train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even using get_dummies, we still get 0's. This might be a result of the original title and text columns having an excess of stopwords."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4afe94f8364f56cdd19798fbe4d9d7a6e296b59974c9e66cfa24f19ae05295b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
